---
title: "Computational Genomics Course \n MDC/BIMSB - 2022 - Capstone Project - Exercises"
author: "YUSUF ENES KAZCI"
output:
  word_document:
    toc: yes
    toc_depth: '2'
  html_document:
    toc: yes
    toc_depth: 2
    toc_float: yes
    number_sections: yes
    code_folding: hide
    theme: readable
    highlight: tango
  pdf_document:
    toc: yes
    toc_depth: '2'
---

`r date()`


```{r setup, include = FALSE}
knitr::opts_chunk$set(eval = FALSE)
```

# Coding 

## Import and explore datasets 

In any data analysis project, it is highly recommended to first do exploratory data analysis to familiarize yourself with the data you are analyzing. It helps you understand the contents of the datasets such as the features, samples, overall distribution of different measurements (such as drug response values).

This section is freestyle. Spend as much time as you see fit to get an understanding of the datasets. 

```{r}
library(tidyverse)

dat <- readRDS("./data.RDS")

### Exploring data:

GDSC <- dat$GDSC

GDSC$gex %>% .[,1:5] %>% head

GDSC$gex %>% dim

### Check NA cells:

GDSC$gex %>% anyNA()

GDSC$cnv %>% .[,1:5] %>% head

GDSC$cnv %>% dim()

GDSC$cnv %>% anyNA()

GDSC$drugs %>% .[,1:5] %>% head

GDSC$drugs %>% dim() 

### we have 11 drugs.

### Check the number of NAs in each column:

apply(GDSC$drugs, MARGIN = 2, FUN = function(x) sum(is.na(x))) %>% table 

### the following code does the same:

colSums(is.na(GDSC$drugs)) %>% table()

### 118 patients do not have any drug data.


GDSC$drugs %>% head()

GDSC$drugs %>% anyNA()

GDSC$drugs[,1:50] %>% boxplot()

### Check the effect of over-scaling:

GDSC$drugs[,1:50] %>% scale() %>% boxplot()

### Look at the distributions of expressions across samples:

GDSC$gex[,c(1:50)] %>% boxplot()

GDSC$cnv[,c(1:50)] %>% boxplot()

###

### Not all patients have response data for all the drugs.
### There are two options that we can proceed with:

### We can subset the patient-drug dataframe only to patients that
### have response variable for all the drugs:

GDSC_drugs_all_11 <- GDSC$drugs %>% 
  select(colnames(.)[colSums(is.na(GDSC$drugs))==0])

GDSC_drugs_all_11 %>% dim()
### we have 246 patients with response variable for all 11 drugs.

### As a second option, I will omit the NA variables for each selected drug
### within the function. Using this option, we can include all the patients
### having a response variable for the selected drug so will not exclude any
### available data.

GDSC_drugs <-GDSC$drugs

### Form a transposed matrix of gene expression dataframe:

tgexp <- t(GDSC$gex)  


####

gCSI <- dat$gCSI

gCSI_test <- gCSI$test

gCSI_test %>% summary

gCSI_holdout <- gCSI$holdout

gCSI_holdout %>% summary

gCSI_drugs <- gCSI$drugs

gCSI_drugs %>% .[,1:5] %>%  head



```

## Setting up the infrastructure

While we build machine learning models, we often want to test many combinations of different ideas and settings. For instance, which omics layer performs as better predictors, which kind of data pre-processing steps yield better results, which kind of machine learning methods are stronger and more robust, so on and so forth. While doing this exercise, if you multiply the kinds of different decisions made at each step, you can easily reach 100s of different ideas tested. A lot of these things will be repetitive and can be simplified by writing functions that can be easily re-used for any combination we are testing.

So, we first need to write some functions that we will use repeatedly. While writing these functions, you will need some actual data so that you can test if the functions work or not. However, while developing the functions, you don't need a very large dataset. You just need a dataset large enough to serve your purposes. This approach of simplifying your dataset by using a small proportion of the actual dataset helps you quickly test your functions and ideas. 


1. **To prepare a data frame that is to be used for building drug response prediction models**

`Input`: The function takes as input a matrix of "omics" measurements (samples on the row, features on the columns),  a data.frame of drug response values (drugs.csv), and the name of the drug (e.g. 'Erlotinib') for which a model is going to be built. 

`Output`: The function should return two data frames: one for training and one for testing. Both data.frames should include the response variable "y", which represents the drug response measurements for the corresponding drug of interest. 

`Hint`: Not all samples are treated with all the drugs in `drugs.csv` file. So you will need to subset the data frames to only include samples without `NA`. 


```{r prepare}
# M: omics data (features on the rows, samples on the columns)


# drugs: table of drug response values (drugs on the rows, 
#samples on the columns)

# drugName: the name of the drug to set as the response variable 



### A function to form a subset from the expression matrix, keeping
### the top 1000 features with the highest variance across patients.

subset_df <- function(mat_data){
  
  ### add also database filtering options.
  
  ### the function can be modified with both options: input <- c("L1000")  or     
  ###c("TRUE")
  
  ### WARNING: I should filter the variables based on variance using only 
  ### the training data. The filtering by variable features should be done
  ### using only training samples.
  
  ### Otherwise, this leads to data leakage from test to training samples. 
  ## So misleadingly, we will get higher performance from this.
  
  ### we will retrieve the indices of the columns ordered based on variances.
  
  top_1000 <- order(matrixStats::colVars(mat_data),decreasing = T)[1:1000]
  mat_data <- mat_data[,top_1000]

  return(mat_data)
}

### Our data preparation function:

prepareDataForModeling <- function(M, drugs, drugName, top1000) {
  
  ### I added an additional input parameter which takes the logical arguement 
  ### if we want to subset our gene expression matrix to top 1000 genes
  ### with the highest variance across the patients.

  
   t_drugs <-t(drugs[row.names(drugs)==drugName,]) ### takes the row of the
   ### specified drug and transpose it to a column.
  
  if (anyNA(t_drugs)) {
     
     t_drugs <-as.data.frame(na.omit(t_drugs))
  }
   
   M <- M[row.names(t_drugs),] ### subset the exp df to the patients w/ drug
   ### response.
   
   M <- cbind(t_drugs[match(row.names(M),row.names(t_drugs)),], M) 
   ### match() function orders according to the left argument, so according
   ### to the data frame which I will add new column with drug response
   ### variables.

  
    ### please set the seed to 1234 here so that everyone gets the 
    ###same train/test split 
  
   set.seed(1234) 

    
    intrain <- caret::createDataPartition(y = M[,1], p = 0.7)[[1]]


  df.train <- M[intrain,]

  df.test <- M[-intrain,]

  if (top1000==TRUE){
     top1000_train_names <-  colnames(subset_df(df.train[,-1])) ### -1 included
     ### because first column includes the drug response values. Genes start 
     ### from the second columns.
 

      ### get logical indices for the 1000 gene columns starting from the
      ### second
      ### column, since the first column contains the added drug response
      ### variables.
      
      top_1000_indices <- colnames(df.train[,-1]) %in% top1000_train_names
      
      df.train <- df.train[, c(TRUE, top_1000_indices)] ### I added TRUE to
      
      ### also include the drug column. 
      
      ### I check if df.train truely contains the data for the top1000 variant
      ### gene:
      
      (df.train[,-1] %>% colnames()) %in% top1000_train_names 
      
      ### I also subset the test data for later use in the prediction part.
      
      df.test <- df.test[, c(TRUE, top_1000_indices)]

 }

      ### I add the drug names to the first columns.

      colnames(df.train)[1] <- drugName
      
      colnames(df.test)[1] <- drugName
        

      return(list('train' = df.train, 'test' = df.test)) 
}

### Some notes and trics about lists in a function try:

### to create the test and train sets for all drugs:

#### my_list <- c()

### for (i in c(1:length(nrow(GDSC_drugs)))) {
# 
#   output_pairs <- prepareDataForModeling(M = tgexp,drugs = GDSC_drugs,
#                                          drugName = row.names(GDSC_drugs)[i])     
#   ### we will add each drug name to its train and test sets' names: 
#   
#   names(output_pairs) <- paste0(paste0(drug_try[i],"_"),names(output_pairs))
#   
#   my_list <- c(my_list, output_pairs)
#   
# }

#  names(my_list)


# [1]"Crizotinib_train""Crizotinib_test" "Dabrafenib_train"  "Dabrafenib_test"  
# [5]"Docetaxel_train"   "Docetaxel_test"    "Erlotinib_train"   "Erlotinib_test"   
# [9]"Ibrutinib_train"   "Ibrutinib_test"    "Lapatinib_train"   "Lapatinib_test"   
#[13]"Paclitaxel_train"  "Paclitaxel_test"   "Palbociclib_train" "Palbociclib_test" 
#[17]"Pictilisib_train"  "Pictilisib_test"   "Vincristine_train" "Vincristine_test" 
#[21]"Vorinostat_train"  "Vorinostat_test"

### we can call an element of a list by its name, just similar to vectors.

### for example:

### my_list["Crizotinib_train"]

# output_mat <- sapply(c(1:22), function(x) dim(my_list[[x]]))
# colnames(output_mat) <- names(my_list)
# output_mat %>% print
```

2. (Optional) **To subset the input features**

The gex/cnv data matrices contain measurements for all protein-coding genes (~20,000 genes). Using all the features in the models will be computationally intensive. Moreover, most genes won't be informative at all. Most methods will struggle with the huge dimensionality of the feature matrices. 

So, filtering the features before using them in a model is advisable. However, this filtering strategy should not be informed by the data in "testing" or "holdout" samples. For instance, one way of filtering the features can be to pick top most variable genes in the training data. Another approach could be to use some prior knowledge such as collections of gene sets that are known to be important in cancer and/or overall drug response. Furthermore, these strategies can be combined with dimension reduction methods such as PCA. While running `caret::train` you can set the pre-processing options to 'pca' to use PCA as the pre-processing step. 

```{r}
# Write a function that subsets a given data.frame
# either using a statistic (e.g. most variable features) or a prior knowledge 
#gene set (e.g. LINCS1000 genes)
# You can also make this a part of `prepareDataForModelling` function



subset_df <- function(mat_data){
  
  ### we will retrieve the indices of the columns ordered based on variances.
  top_1000 <- order(matrixStats::colVars(mat_data),decreasing = T)[1:1000]
  mat_data <- mat_data[,top_1000]

  return(mat_data)
}

### NOTE: If I use subsetting in the training data, I will need to make the
### prediction on the same genes in the test set.

```


3. **To build drug response prediction models (given a training data frame prepared in 1&2) using `caret` library.** 

`Input`: This function should take a training data (including omics features and drug response values)

`Output`: Return the model fit using methods such as "ranger", "glmnet", "svmLinear/svmRadial", or any other method of interest for which you have available libraries. 

`Hint`: You can write a single function that is flexible and can accommodate any method or argument that can be used in `caret`. You can also write multiple functions (i.e. one function per method where you hard-code method specific settings specifically for each method)

```{r model}

#### I can later use the expand.grid() function which creates a data.frame
### from all combinations of the supplied vectors or factors. 

#### random forest model with the default parameters.

### t_control argument will take the train control parameters.
### t_control <- caret::trainControl(method = "cv",number = 5)

### Add option for elastic net, knn fit and ranger.

fit_model <- function(train_data, t_control){

  set.seed(1234)
  
  ### I will try thre methods for regression: random forest, kNN, and 
  ### elastic net. Later, I can add try "svmLinear/svmRadial" method.
  
  ### we can supply the number to the tuneLength argument of the care::train
  ### function. 
  
  ### The tuneLength parameter tells the algorithm to try different default 
  ### values for the main parameter
  
  ### As an alternative, we can use tuneGrid arguement which gets a data.frame
  ### conatining specific arguements of each method selected in the
  ### caret::train function.
  
  tuneLength_RF <- 3  ### I WILL DO IT 10 LATER.
  
  #### tuneGrid_RF = data.frame(mtry = 100,min.node.size = 1,
  ##splitrule = c("variance"))

  m_fit_RF <- caret::train(x=train_data[,-1], y=train_data[,1],method="ranger",
                        trControl=t_control,
                        importance="impurity", # calculate importance
                        # tuneGrid = tuneGrid_RF ### we can also use this.
                        tuneLength=tuneLength_RF)

  
  ### The tuneLength parameter tells the algorithm to try different default 
  ### values for the main parameter
  
  
  ### tuneGrid_ENET = data.frame(alpha=0.5,lambda=seq(0.1,0.7,0.05))
  # alpha and lambda parameters to try 
  
  tuneLength_ENET <- 3
  
  m_fit_enet <- caret::train(x=train_data[,-1],y=train_data[,1],
                            method="glmnet",
                            trControl=t_control,
                            importance="impurity", # calculate importance
                             # or we can give:
                            ## tuneGrid=tuneGrid_ENET
                            tuneLength=tuneLength_ENET)
  
  tuneLength_KNN <- 3
  
  ### tuneGrid_KNN = data.frame(k=2:7) # try k between 2-7

  m_fit_KNN <- caret::train(x=train_data[,-1], y=train_data[,1],method="knn",
                            trControl=t_control,
                            importance="impurity", # calculate importance
                            ###tuneGrid = tuneGrid_KNN
                            tuneLength=tuneLength_KNN)
  
  model_outputs <- c()
  
  ### One option is to add each by setting their names, separately.
  
  # model_outputs[["RF"]] <- m_fit_RF
  # model_outputs[["ENET"]] <- m_fit_enet
  # model_outputs[["KNN"]] <- m_fit_KNN
  
  ### other option:  
  
  model_outputs <- c()
  
  model_outputs <- c( model_outputs, list(RF= m_fit_RF,ENET=m_fit_enet, KNN=m_fit_KNN))
  return(model_outputs)
  
}

```

4. **To evaluate the built models.**

`Input`: A model built as in step 3 and a test dataset (as prepared in step 1&2 - or prepared using other means). The testing data frame must be a subset of the set of features used for training the input model and should contain a column that contains the drug response values (i.e. "y"), otherwise the model evaluation won't work. 

`Output`: Return a table of metrics such as `Rsquare` or `Correlation Coefficient`, which reflects how well the predicted drug response values using the input model match with the observed drug response values provided in the testing data frame. 

`Hint`: See `caret::COR` or `caret::R2`


```{r evaluate}

test_model <- function(model_fit, test_data){
  
  
  
  predict_data <- predict(object = model_fit, newdata=test_data[,-1])
  ### 
  
  
  return(caret::postResample(pred = predict_data, obs = test_data[,1]))

}


```

5. **To return a table of features sorted by importance**. 

The importance score of a feature reflects how much of the prediction accuracy is dependent on that feature for the specific prediction task. Most important features can be used as "biomarkers" of drug response. 

`Input`: A model built as in step 3. 

`Output`: A table of variable importance scores, where the features are on the rows and the column represents the variable importance. Optionally, the table could be sorted by importance scores, so the most important features appear on top. 

`Hint`: See `caret::varImp`


```{r varimp}

var_import <- function(model_fit){
  
  varImp_df <- caret::varImp(model_fit)
  
  ### ordering by importance scores:
  
  varImp_df <- varImp_df$importance[order(varImp_df$importance$Overall,
  decreasing = TRUE),, drop=FALSE]
  
  return(varImp_df)
  
} 


```

## Within dataset prediction

If you managed to write the four functions, now you should be ready to do some real data analysis. 

We start by doing a within-dataset analysis, where we build models on only `GDSC` dataset. 

Here is the pseudo-code of what you need to do:

```
# import data
Import the `gex.csv`, `cnv.csv`, and `drugs.csv` data from `GDSC`. 


# model
for each `drug` in `drugs.csv`
  for each `omics` layer (gex.csv or cnv.csv)
     - Prepare the data for modeling (as in Step 1 in above section)
     split into 70% as training and 30% as testing data.
     
     for each `feature selection strategy` 
     (e.g. take top most variable features, or use prior information (Cancer Hallmarks/LINCS1000 genes)
       - preprocess the training data (subset the training data)
     
        for each `method` (ranger, glmnet, svmLinear, or ...)
      
            - build a model on training data (use 5-fold cross-validation)
            - evaluate the model on testing data 
            - compute variable importance metrics for the model 

# collate results
Finally, combine the results from this analysis in a table so that you can find the best combinations for each drug. 

# visualize results
Make plots to summarise the results by drug/omics type/procedure

```

`Hint 1`: In order not to be overwhelmed by the for-loops, first pick one setup and make sure it works. 
For example, build a "glmnet" model for "Erlotinib" using "gex" features that overlap with LINCS1000 genes. 
Once you get this done, you can build the loops for other drugs, other omics layers, other feature subsetting operations. 

`Hint 2`: You can add more loops here. For example you can use different kinds of tuningGrid options, different kinds of 
feature preprocessing options (such as scale/center/nzv/PCA). 

`Hint 3`: See `expand.grid` function if you don't want to write too many nested loops

`Hint 4`: Feel free to use multiple code chunks if it looks more organized
```{r within_dataset}

# import data:

### Import the `gex.csv`, `cnv.csv`, and `drugs.csv` data from `GDSC`. 

library(tidyverse)

dat <- readRDS("./data.RDS")

### reading gene expression matrix.

gex <- dat$GDSC$gex

### Form a transposed version:

t_gexp <- t(gex) 

t_gexp %>% head %>% .[1:5,1:5]

### Same steps applied for the CNV data:

cnv <- dat$GDSC$cnv

t_cnv <- t(cnv)

t_cnv %>% head %>% .[1:5,1:5]

### read the patient x drug response data frame:

GDSC_drugs <- dat$GDSC$drugs

# model for each `drug` in `drugs.csv` for each `omics` layer (gex.csv or 
### cnv.csv) 


# -Prepare the data for modeling (as in Step 1 in above section) split into 
### 70% #as training and 30% as testing data. for each `feature selection 
###strategy` #(e.g. take top most variable features, or use prior information 
###(Cancer #Hallmarks/LINCS1000 genes) 

 my_prep_data_list_GEXP <- c()
 
 my_prep_data_list_CNV <- c()

 
for (i in 1:nrow(GDSC_drugs)) {
  
 GEX_prep_data <- prepareDataForModeling(M = t_gexp, drugs = GDSC_drugs, 
                          drugName = row.names(GDSC_drugs)[i],top1000 = TRUE)
 
 CNV_prep_data <-  prepareDataForModeling(M = t_cnv, drugs = GDSC_drugs, 
                       drugName = row.names(GDSC_drugs)[i], top1000 = TRUE)
 
 ### we will add each drug name to its train and test sets' names: 
 
 drugName <- row.names(GDSC_drugs)[i]
 
 names(GEX_prep_data) <- paste0(paste0(drugName,"_"),names(GEX_prep_data))
 
 names(CNV_prep_data) <- paste0(paste0(drugName,"_"),names(CNV_prep_data))
 
    
 my_prep_data_list_GEXP <- c(my_prep_data_list_GEXP, GEX_prep_data)
 
 my_prep_data_list_CNV <- c(my_prep_data_list_CNV, CNV_prep_data)
 
}


# - preprocess the training data (subset the training data) for each `method` 
 #(ranger, glmnet, svmLinear, or ...) - build a model on training data 
 #(use #5-fold cross-validation) 

t_control <- caret::trainControl(method = "cv",number = 2) ### I WILL CHANGE:


 my_model_list_GEXP <- c()
 
 my_model_list_CNV <- c()

 i <- 1  ### I will take only the training sets for each drug which are stored 
 #in the odd numbers (i.e. 1,3,5.....21).
 
while(i <= 4)  { ###length(my_prep_data_list_CNV -I WILLL CHANGE:
  
  
  ###length(my_prep_data_list_CNV) both CNV and GEXP lists are of same length 
  ### so we #can iterate up to the length of either.
  
  mod_fit_gexp <- fit_model(train_data = my_prep_data_list_GEXP[[i]],
                            t_control = t_control) 
  
  mod_fit_CNV <- fit_model(train_data = my_prep_data_list_CNV[[i]],
                            t_control = t_control) 
   
 
  
### WARNING: Double brackets were used to access the first element of the     
  #list which contains our train dataset which is classed as ("matrix" "array").
  
  my_model_list_GEXP[[names(my_prep_data_list_GEXP[i])]] <- mod_fit_gexp
  
  my_model_list_CNV[[names(my_prep_data_list_CNV[i])]] <- mod_fit_CNV
  
### we add the model for each drug to the list by assigning its name at the 
#left.
  
### single bracket was used to access the name of the list that contains the 
#training matrix as its only element.

  i <- i+2
}

    
# - evaluate the model on testing data 

 metrics_gexp <- c()
 
 metrics_CNV <- c()
 
for (i in 1:length(my_model_list_GEXP)) {
  
     
 ### I create names for each metric that contains the drug name and the data 
  #type. Each model is named as  " 'drug name'_train " e.g. "Crizotinib_train". 
  #I take only the part of the name before the "_" character. It is the first 
  #element of the out put vector with two elements, from strsplit() function.
  
  ### Next I add "_gexp" and "_CNV" ,respectively, to the each metric element.
     
     name_gexp <- paste0( unlist(strsplit(names(my_model_list_GEXP[i]),
                                          split = "_"))[1])
     
     
      ### same for CNV test data for each drug:
      
      ### Actually, CNV test names are same with GEXP test names but I will 
      ### form #new variable to avoid confusion. 
      
     name_CNV <-  paste0( unlist(strsplit(names(my_model_list_CNV[i]),
                                          split = "_"))[1]) 
   
     

     
     ### Apply the test_model function to the test data to calculate the RMSE 
     #and R2 metrics and add them to the list object as a named variable:
     
     
      ### get the name of the test variable to supply as parameter to the 
     #test_data argument: 
     
      test_gexp <-
          names(my_prep_data_list_GEXP)[grepl(x=names(my_prep_data_list_GEXP), 
                                                         pattern = "test")][i]

      test_CNV <-
          names(my_prep_data_list_CNV)[grepl(x= names(my_prep_data_list_CNV), 
                                                         pattern = "test")][i] 
      ### Apply the test_model function:
      

      for (k in c(1:length(my_model_list_GEXP [[i]]))) { 
        ### number of methods use i.e. 3 (KNN,RF,ENET).
        
        ### I will form names for the 3 different model objects iteratively,
        ### I will add the calculated prediction errors for each model for each
        ### drug.
        
        name_model_gexp <- names(my_model_list_GEXP [[i]][k])
        
        metrics_gexp[[name_gexp]][[ name_model_gexp ]] <-   
                        test_model(model_fit=my_model_list_GEXP[[i]][[k]],
                              test_data = my_prep_data_list_GEXP[[test_gexp]])
        
        
        name_model_CNV <- names(my_model_list_CNV [[i]][k])
        
        metrics_CNV[[name_CNV]][[name_model_CNV]] <- 
                        test_model(model_fit = my_model_list_CNV[[i]][[k]],
                              test_data = my_prep_data_list_CNV[[test_CNV]])
        
        
      }

     
}
 



# - compute variable importance metrics for the model # collate (compare) 
 #results Finally, combine the results from this analysis in a table so that 
 #you #can find the best combinations for each drug. 

 
var_imp_gexp <- c()

var_imp_cnv <- c()


for (i in 1:length(my_model_list_CNV)) {
  
  
  ### assigning names to each variable importance data frame:
  
   name_gexp <- paste0( unlist(strsplit(names(my_model_list_GEXP[i]),
                                  split = "_"))[1])
  
   name_CNV <-  paste0( unlist(strsplit(names(my_model_list_CNV[i]),
                                  split = "_"))[1]) 
   
   
  ### Form important variables data frames:
   
  
  ### For gexp models:
   
   
   for (k in 1:length(my_model_list_GEXP[[i]])) {
     
  
     name_model_gexp <- names(my_model_list_GEXP[[i]][k])
     
     name_model_CNV <- names(my_model_list_CNV[[i]][k])
     
     
  var_imp_gexp[[ name_gexp ]][[ name_model_gexp ]] <- 
                    var_import(model_fit = my_model_list_GEXP[[i]][[k]])
 
   ### For cnv models:
  
  var_imp_cnv[[  name_CNV ]][[name_model_CNV ]] <- 
                    var_import(model_fit = my_model_list_CNV[[i]][[k]])

   }
    
}


### Plot the model tuning parameters by using plot function:

### we can supply any model object of caret train class as an argument:



for (i in 1:length(my_model_list_GEXP)) {
  
  for (k in 1:length(my_model_list_GEXP[[i]])) {
     
    
    
    name_image <- paste0(names((my_model_list_GEXP[i])),
                                    " with ",names(my_model_list_GEXP[[i]][k]))
     # 1. Open png file
      png(paste0(getwd(),"/plots/",name_image,".png"))
      
      # 2. Create the plot
    
         p <- plot(my_model_list_GEXP[[i]][[k]],
                          main=name_image)

         print(p) 
          
          
            # 3. Close the file
      dev.off()
  
  }

  for (k in 1:length(my_model_list_CNV[[i]])) {
    
    

    
      name_image <- paste0(names((my_model_list_CNV[i])),
                                    " with ",names(my_model_list_CNV[[i]][k]))    

       # 1. Open png file
       png(paste0(getwd(),"/plots/",name_image,".png"))
      
      # 2. Create the plot

     p <- plot(my_model_list_CNV[[i]][[k]],
              main=name_image)

        print(p) 
            
       
      # 3. Close the file
      dev.off()
  
  }
  
  
}

 
### I will write a function to form a summary data frame from the metrics of 
#each model.

# visualize results Make plots to summarize the results by drug/omics 
#type/procedure 

### top 10 important variables plot for each drug and omics type will
### be plotted.



# ``` `Hint 1`: In order not to be overwhelmed by the for-loops, first pick one 
#setup and make sure it works. For example, build a "glmnet" model for
#"Erlotinib" using "gex" features that overlap with LINCS1000 genes. Once you
#get this done, you can build the loops for other drugs, other omics layers, 
#other feature subsetting operations. 

# `Hint 2`: You can add more loops here. For example you can use different kinds 
#of tuningGrid options, different kinds of feature preprocessing options (such 
#as scale/center/nzv/PCA). 

# `Hint 3`: See `expand.grid` function if you don't want to write too many 
#nested loops 


# `Hint 4`: Feel free to use multiple code chunks if it looks more organized

```



## Cross-dataset prediction

Now, we would like to also predict drug response values in an external dataset. Validating your findings in an external dataset gives more reliability to your analysis. Therefore, we provide a dataset with matching features, omics layers, and drug response values (gCSI dataset). 

For this exercise, we will re-use the models that we built during the `within-dataset prediction` exercise. 
We use `gCSI/test` data to pick the best model and use the best model to evaluate on the `gCSI/holdout` data. 

Here is what we'd like to do:

```
Import the "test" portion of the gCSI dataset (`data/gCSI/test`) 
Import the "holdout" portion of the gCSI dataset (`data/gCSI/holdout`)
1. For each model built for GDSC dataset in **within-dataset prediction** exercise
    Evaluate the model on `gCSI/test` data (for corresponding omics/drug combination)
2. Pick the best approach for each drug from step 1. Evaluate it on `gCSI/holdout` data (for corresponding omics/drug combination) (Assuming you have saved the model corresponding to each experiment).
3. Collate and visualize the results 
```

```{r cross-dataset-test}

### We form the objects containing the test and holdout datasets and the drugs 
#data.

gCSI <- dat$gCSI

gCSI_test <- gCSI$test

gCSI_holdout <- gCSI$holdout

gCSI_drugs <- gCSI$drugs


### 1. For each model built for GDSC dataset in **within-dataset prediction** 
#exercise, Evaluate the model on `gCSI/test` data (for corresponding omics/drug
#combination)

### we get expression and CNVdata for the test group:

gCSI_test_gex <- gCSI_test$gex

gCSI_test_cnv <- gCSI_test$cnv

### transpose them:


t_gexp_gCSI <- t(gCSI_test_gex)

t_CNV_gCSI <- t(gCSI_test_cnv)


### I check the number of features in the gCSI dataset to see whether they are 
#same with the GDSC datasets:

### gCSI dataset dimensions:
  
t_gexp_gCSI  %>% dim()

t_CNV_gCSI  %>% dim()

### GDSC dataset dimensions:

t_gexp %>% dim()

t_cnv %>% dim()

###########################

### Check the dimension of the gCSI drug data frame:

gCSI_drugs %>% dim()

### we have 310 patients and 11 drugs.

### 150 of 310 patients are hosted in the gCSI test group.

### 160 of 310 patients are hosted in the gCSI holdout group.

### Prepare the gCSI data to be used with the models:

### we get the names of the top 1000 genes used in modelling previously in the 
#GDSC dataset:

model_used_gene_gexp <- colnames(GEX_prep_data$Vorinostat_train)[-1] ### we take 
#all the names corresponding to the genes except the firs column which contains 
#the drug name for this train data frame.

model_used_gene_CNV <- colnames(CNV_prep_data$Vorinostat_train)[-1]

t_gexp_gCSI_subset <- t_gexp_gCSI[,model_used_gene_gexp]

t_CNV_gCSI_subset <-  t_CNV_gCSI[,model_used_gene_CNV]

### I need to subset also the gCSI drug data frame since it contains the paients 
#from the both test and the holdout groups. I will subset it to the patients who
#are used in the gCSI test set.

gCSI_drugs_test <- gCSI_drugs[,row.names(t_gexp_gCSI_subset)]



### I will write a function to prepare the gCSI test data:

prepare_without_split <- function(M, drugs, drugName) {
  

   t_drugs <-t(drugs[row.names(drugs)==drugName,]) ### takes the row of the 
   #specified drug and transpose it to a column.
  
  if (anyNA(t_drugs)) {
     
     t_drugs <-as.data.frame(na.omit(t_drugs))
  }
   
   M <- M[row.names(t_drugs),] ### subset the exp df to the patients w/ drug
   ### response.
   
   M <- cbind(t_drugs[match(row.names(M),row.names(t_drugs)),], M) ### match() 
   #functions order according to the left argument.

   
   colnames(M)[1] <- drugName ### add the name of the drug to the first column 
   #including drug response values for each patient.
   
   return(M)
    
}


 my_gCSI_data_list_gexp <- c()
 my_gCSI_data_list_CNV <- c()
 
for (i in 1:nrow( gCSI_drugs_test)) {
  
 GEX_prep_gCSI <- prepare_without_split(M = t_gexp_gCSI_subset, 
            drugs = gCSI_drugs_test, drugName = row.names(gCSI_drugs_test)[i])
 
 CNV_prep_gCSI <-  prepare_without_split(M = t_CNV_gCSI_subset, 
            drugs = gCSI_drugs_test, drugName = row.names(gCSI_drugs_test)[i])
 
 
 name_gexp_gCSI <- paste0(row.names(gCSI_drugs_test)[i],"_gCSI","_test","_gexp")
 
 my_gCSI_data_list_gexp[[name_gexp_gCSI ]] <- GEX_prep_gCSI
 
 name_CNV_gCSI <- paste0(row.names(gCSI_drugs_test )[i],"_gCSI","_test","_CNV")
 
 my_gCSI_data_list_CNV[[name_CNV_gCSI ]] <- CNV_prep_gCSI
 
}


###  Evaluation of the models on `gCSI/test` data (for corresponding omics/drug 
 ### combination)

 metrics_gCSI_test_gexp <- c()
 
 metrics_gCSI_test_CNV <- c()
 
for (i in 1:length(my_model_list_GEXP)) {
  
  
metrics_gCSI_test_gexp[[names(my_gCSI_data_list_gexp[i])]] <- 
  test_model(model_fit = my_model_list_GEXP[[i]],
             test_data = my_gCSI_data_list_gexp[[i]]) 
  
  
metrics_gCSI_test_CNV[[names(my_gCSI_data_list_CNV[i])]] <- 
  test_model(model_fit = my_model_list_CNV[[i]],
             test_data = my_gCSI_data_list_CNV[[i]]) 
  
}
 
### 2. Pick the best approach for each drug from step 1. Evaluate it on `
###gCSI/holdout` data (for corresponding omics/drug combination) (Assuming you
 ### have saved the model corresponding to each experiment). 
 
 
### Prepare the data of the holdout group:
 
gCSI_holdout_gex <- gCSI_holdout$gex

gCSI_holdout_cnv <- gCSI_holdout$cnv


### transpose them:


t_gCSI_holdout_gex <- t(gCSI_holdout_gex)

t_gCSI_holdout_cnv  <- t(gCSI_holdout_cnv)


### I check the number of features in the gCSI dataset to see whether they are 
### same with the GDSC datasets:

### gCSI holdout dataset dimensions:
  
t_gCSI_holdout_gex  %>% dim()

t_gCSI_holdout_cnv  %>% dim()


t_gCSI_holdout_gex_subset <- t_gCSI_holdout_gex[,model_used_gene_gexp]

t_gCSI_holdout_cnv_subset <-  t_gCSI_holdout_cnv[,model_used_gene_CNV]

### I need to subset also the gCSI drug data frame since it contains the paients
### from the both test and the holdout groups. I will subset it to the patients
### who are used in the gCSI test set.

gCSI_drugs_holdout <- gCSI_drugs[,row.names(t_gCSI_holdout_gex_subset)]
 

### prepare the data before the evaluation of the model:

 my_gCSI_data_list_HOLDOUT_gexp <- c()
 my_gCSI_data_list_HOLDOUT_CNV <- c()
 
for (i in 1:nrow( gCSI_drugs_holdout)) {
  
 GEX_prep_gCSI_holdout <- prepare_without_split(M = t_gCSI_holdout_gex_subset ,
                                drugs = gCSI_drugs_holdout, 
                                drugName = row.names(gCSI_drugs_holdout)[i])

 CNV_prep_gCSI_holdout <-  prepare_without_split(M = t_gCSI_holdout_cnv_subset,
                                 drugs = gCSI_drugs_holdout, 
                                 drugName = row.names(gCSI_drugs_holdout)[i])
 
 
 name_gexp_gCSI_hold_out <- paste0(row.names( gCSI_drugs_holdout )[i],
                                   "_gCSI","_holdout" ,"_gexp")
 
 my_gCSI_data_list_HOLDOUT_gexp[[name_gexp_gCSI_hold_out ]] <- 
   GEX_prep_gCSI_holdout
 
 name_CNV_gCSI_holdout <- paste0(row.names( gCSI_drugs_holdout )[i],
                                 "_gCSI","_holdout","_CNV" )
 
 my_gCSI_data_list_HOLDOUT_CNV[[name_CNV_gCSI_holdout ]] <- 
   CNV_prep_gCSI_holdout
 
}

### I will apply the same model on them for now. But later I will add additional
### elastic net and knn fit in addition to random forest.
 
 ###  Evaluation of the models on `gCSI/test` data (for corresponding omics/drug
 ###combination)

 metrics_gCSI_HD_gexp <- c()
 
 metrics_gCSI_HD_CNV <- c()
 
for (i in 1:length(my_model_list_GEXP)) {
  
  
    metrics_gCSI_HD_gexp[[names(my_gCSI_data_list_HOLDOUT_gexp[i])]] <- 
      test_model(model_fit = my_model_list_GEXP[[i]],
                 test_data = my_gCSI_data_list_HOLDOUT_gexp[[i]]) 
  
  
     metrics_gCSI_HD_CNV [[names(my_gCSI_data_list_HOLDOUT_CNV[i])]] <- 
       test_model(model_fit = my_model_list_CNV[[i]],
                  test_data = my_gCSI_data_list_HOLDOUT_CNV[[i]]) 
  
}







```


```{r cross-dataset-holdout}

```



# Final Results

For both within-dataset and cross-dataset exercises, report the `Correlation Coefficient` of the predicted vs observed drug response values. 


```{r collate_final_results}
# summary results for each drug from within-dataset-prediction (GDSC->test )

### correlation coefficients

# summary results for each drug from cross-dataset-prediction (gCSI -> holdout)

### correlation coefficients

```




  
  